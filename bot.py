import os
import logging
import base64
import tempfile
import requests
import time
import datetime
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from telegram.constants import ParseMode
import openai
from dotenv import load_dotenv
from io import BytesIO
import database
import summarizer
import web_search
import web_extractor
import usage_limits
import memory
import exchange_rates  # Import the new exchange_rates module
import re

# Load environment variables from .env file
load_dotenv()

# Enable logging
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logger = logging.getLogger(__name__)

# Set up OpenAI API key
openai.api_key = os.getenv("OPENAI_API_KEY")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Send a message when the command /start is issued."""
    user = update.effective_user
    await update.message.reply_html(
        f"ÿ≥ŸÑÿßŸÖ {user.mention_html()}! ŸÖŸÜ ŸÅ€åÿ±ÿ™€åŸÇ Ÿáÿ≥ÿ™ŸÖ. ÿ®ÿ±ÿß€å ÿØÿ±€åÿßŸÅÿ™ Ÿæÿßÿ≥ÿÆÿå ŸÖŸÜ ÿ±Ÿà ÿ®ÿß @firtigh ÿØÿ± Ÿæ€åÿßŸÖ ÿÆŸàÿØ ÿ™⁄Ø ⁄©ŸÜ€åÿØ."
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Send a message when the command /help is issued."""
    help_text = (
        "ÿ®ÿ±ÿß€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ŸÅ€åÿ±ÿ™€åŸÇÿå ÿ®Ÿá €å⁄©€å ÿßÿ≤ ÿß€åŸÜ ÿ±Ÿàÿ¥‚ÄåŸáÿß ÿπŸÖŸÑ ⁄©ŸÜ€åÿØ:\n\n"
        "1. ŸÖŸÜ ÿ±Ÿà ÿ®ÿß @firtigh €åÿß ŸÅ€åÿ±ÿ™€åŸÇ ÿØÿ± Ÿæ€åÿßŸÖ ÿÆŸàÿØ ÿ™⁄Ø ⁄©ŸÜ€åÿØ.\n"
        "2. ÿ®Ÿá €å⁄©€å ÿßÿ≤ Ÿæ€åÿßŸÖ‚ÄåŸáÿß€å ŸÖŸÜ ŸÖÿ≥ÿ™ŸÇ€åŸÖ Ÿæÿßÿ≥ÿÆ ÿØŸá€åÿØ.\n\n"
        "*ŸÇÿßÿ®ŸÑ€åÿ™‚ÄåŸáÿß€å Ÿà€å⁄òŸá:*\n"
        "‚Ä¢ *ÿÆŸÑÿßÿµŸá ⁄ØŸÅÿ™⁄ØŸàŸáÿß*: ŸÖ€å‚Äåÿ™ŸàÿßŸÜ€åÿØ ÿßÿ≤ ŸÖŸÜ ÿØÿ±ÿÆŸàÿßÿ≥ÿ™ ÿÆŸÑÿßÿµŸá ⁄ØŸÅÿ™⁄ØŸàŸáÿß€å ⁄Øÿ±ŸàŸá ÿ±ÿß ÿ®⁄©ŸÜ€åÿØ. ŸÖÿ´ÿßŸÑ: '@firtigh ÿÆŸÑÿßÿµŸá ÿ®ÿ≠ÿ´‚ÄåŸáÿß€å ÿ≥Ÿá ÿ±Ÿàÿ≤ ÿßÿÆ€åÿ± ⁄Ü€åŸáÿü'\n"
        "‚Ä¢ *ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å ÿß€åŸÜÿ™ÿ±ŸÜÿ™€å*: ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ⁄©ŸÑŸÖÿßÿ™€å ŸÖÿ´ŸÑ 'ÿ¨ÿ≥ÿ™ÿ¨Ÿà'ÿå 'ÿ≥ÿ±⁄Ü' €åÿß '⁄ØŸà⁄ØŸÑ'ÿå ÿßÿ≤ ŸÖŸÜ ÿ®ÿÆŸàÿßŸá€åÿØ ÿß€åŸÜÿ™ÿ±ŸÜÿ™ ÿ±ÿß ÿ¨ÿ≥ÿ™ÿ¨Ÿà ⁄©ŸÜŸÖ. ŸÖÿ´ÿßŸÑ: '@firtigh ÿ¨ÿ≥ÿ™ÿ¨Ÿà ⁄©ŸÜ ÿ¢ÿÆÿ±€åŸÜ ÿßÿÆÿ®ÿßÿ± ÿß€åÿ±ÿßŸÜ'\n"
        "‚Ä¢ *ÿßÿÆÿ®ÿßÿ± ŸÅÿßÿ±ÿ≥€å*: ÿ®ÿ±ÿß€å ÿ≥ŸàÿßŸÑÿßÿ™ ÿÆÿ®ÿ±€åÿå ŸÖŸÜÿßÿ®ÿπ ÿÆÿ®ÿ±€å ŸÅÿßÿ±ÿ≥€å‚Äåÿ≤ÿ®ÿßŸÜ ÿØÿ± ÿßŸàŸÑŸà€åÿ™ ŸÇÿ±ÿßÿ± ŸÖ€å‚Äå⁄Ø€åÿ±ŸÜÿØ. ŸÖÿ´ÿßŸÑ: '@firtigh ÿßÿÆÿ®ÿßÿ± ÿßŸÖÿ±Ÿàÿ≤ ⁄Ü€åŸáÿü'\n"
        "‚Ä¢ *ÿ™ÿ≠ŸÑ€åŸÑ ŸÑ€åŸÜ⁄©*: ÿß⁄Øÿ± ŸÑ€åŸÜ⁄©€å ÿØÿ± Ÿæ€åÿßŸÖ ÿÆŸàÿØ ŸÇÿ±ÿßÿ± ÿØŸá€åÿØÿå ŸÖŸÜ ŸÖÿ≠ÿ™Ÿàÿß€å ÿ¢ŸÜ ÿ±ÿß ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ Ÿà ÿ™ÿ≠ŸÑ€åŸÑ ŸÖ€å‚Äå⁄©ŸÜŸÖ.\n"
        "‚Ä¢ *ÿ™ÿ≠ŸÑ€åŸÑ ÿ™ÿµÿßŸà€åÿ±*: ŸÖ€å‚Äåÿ™ŸàÿßŸÜ€åÿØ ÿ™ÿµŸà€åÿ± €åÿß GIF ÿßÿ±ÿ≥ÿßŸÑ ⁄©ŸÜ€åÿØ Ÿà ŸÜÿ∏ÿ± ŸÖŸÜ ÿ±ÿß ÿ®Ÿæÿ±ÿ≥€åÿØ.\n"
        "‚Ä¢ *ŸÜÿ±ÿÆ ÿßÿ±ÿ≤*: ŸÖ€å‚Äåÿ™ŸàÿßŸÜ€åÿØ ÿßÿ≤ ŸÖŸÜ ŸÇ€åŸÖÿ™ ÿØŸÑÿßÿ± ÿ®Ÿá ÿ™ŸàŸÖÿßŸÜ ÿ±ÿß ÿ®Ÿæÿ±ÿ≥€åÿØ €åÿß ÿßÿ≤ ÿØÿ≥ÿ™Ÿàÿ± /dollar ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ.\n"
        "‚Ä¢ *ŸÖÿ≠ÿØŸàÿØ€åÿ™ ÿßÿ≥ÿ™ŸÅÿßÿØŸá*: ÿ®ÿ±ÿß€å ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å ÿß€åŸÜÿ™ÿ±ŸÜÿ™€å Ÿà ÿ™ÿ≠ŸÑ€åŸÑ ÿ™ÿµÿßŸà€åÿ± ŸÖÿ≠ÿØŸàÿØ€åÿ™ ÿ±Ÿàÿ≤ÿßŸÜŸá Ÿàÿ¨ŸàÿØ ÿØÿßÿ±ÿØ (ÿ™ŸÜÿ∏€åŸÖ‚ÄåŸæÿ∞€åÿ±).\n"
        "‚Ä¢ *⁄ØŸÅÿ™⁄ØŸà€å ŸáŸàÿ¥ŸÖŸÜÿØ*: ŸÖ€å‚Äåÿ™ŸàÿßŸÜ€åÿØ ÿ®Ÿá ÿµŸàÿ±ÿ™ ŸÖÿ≠ÿßŸàÿ±Ÿá‚Äåÿß€å ÿ®ÿß ŸÖŸÜ ⁄ØŸÅÿ™⁄ØŸà ⁄©ŸÜ€åÿØ Ÿà ÿ≥ŸàÿßŸÑÿßÿ™ ŸÖÿÆÿ™ŸÑŸÅ ÿ®Ÿæÿ±ÿ≥€åÿØ.\n\n"
        "*ŸÇÿßÿ®ŸÑ€åÿ™‚ÄåŸáÿß€å ÿ≠ÿßŸÅÿ∏Ÿá Ÿà ÿßÿ∑ŸÑÿßÿπÿßÿ™€å:*\n"
        "‚Ä¢ *ÿ≠ÿßŸÅÿ∏Ÿá ⁄Øÿ±ŸàŸá€å*: ŸÖŸÜ ŸÖ⁄©ÿßŸÑŸÖÿßÿ™ ŸÖŸáŸÖ ⁄Øÿ±ŸàŸá ÿ±ÿß ÿ®Ÿá ÿÆÿßÿ∑ÿ± ŸÖ€å‚Äåÿ≥Ÿæÿßÿ±ŸÖ Ÿà ŸÖ€å‚Äåÿ™ŸàÿßŸÜŸÖ ÿßÿ≤ ÿ¢ŸÜŸáÿß ÿØÿ± Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß€åŸÖ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜŸÖ.\n"
        "‚Ä¢ *Ÿæÿ±ŸàŸÅÿß€åŸÑ ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ*: ŸÖŸÜ ÿπŸÑÿß€åŸÇ Ÿà Ÿà€å⁄ò⁄Ø€å‚ÄåŸáÿß€å ⁄©ÿßÿ±ÿ®ÿ±ÿßŸÜ ÿ±ÿß €åÿßÿØ ŸÖ€å‚Äå⁄Ø€åÿ±ŸÖ ÿ™ÿß ÿ®ÿ™ŸàÿßŸÜŸÖ Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß€å ÿ¥ÿÆÿµ€å‚Äåÿ≥ÿßÿ≤€å ÿ¥ÿØŸá ÿ®ÿØŸáŸÖ.\n"
        "‚Ä¢ *ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿ®Ÿá‚Äåÿ±Ÿàÿ≤*: ŸÇÿßÿØÿ± ÿ®Ÿá ÿ¨ÿ≥ÿ™ÿ¨Ÿà Ÿà ÿßÿ±ÿßÿ¶Ÿá ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ ÿßÿ≤ ÿß€åŸÜÿ™ÿ±ŸÜÿ™ Ÿáÿ≥ÿ™ŸÖ.\n"
        "‚Ä¢ *ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ŸÖÿ≠ÿ™Ÿàÿß*: ŸÖ€å‚Äåÿ™ŸàÿßŸÜŸÖ ŸÖÿ≠ÿ™Ÿàÿß€å ŸÖŸÅ€åÿØ ÿßÿ≤ ÿµŸÅÿ≠ÿßÿ™ Ÿàÿ® ÿ±ÿß ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ Ÿà ÿÆŸÑÿßÿµŸá ⁄©ŸÜŸÖ.\n\n"
    )
    
    try:
        await update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)
    except Exception:
        # Fall back to plain text if Markdown fails
        await update.message.reply_text(help_text.replace('*', ''))

async def is_serious_question(text: str) -> bool:
    """Determine if a message appears to be a serious question."""
    serious_indicators = [
        '?', '⁄Üÿ∑Ÿàÿ±', '⁄Ü⁄ØŸàŸÜŸá', 'ÿ¢€åÿß', '⁄Üÿ±ÿß', '⁄©€å', '⁄©ÿ¨ÿß', '⁄ÜŸá', '⁄ÜŸÜÿØ',
        'help', 'problem', 'issue', 'error', 'ŸÖÿ¥⁄©ŸÑ', 'ÿÆÿ∑ÿß', '⁄©ŸÖ⁄©'
    ]
    
    # Check if any serious indicators are in the text
    for indicator in serious_indicators:
        if indicator in text.lower():
            return True
            
    return False

async def generate_ai_response(prompt: str, is_serious: bool, image_data=None, search_results=None, web_content=None, chat_id=None, user_id=None, additional_images=None) -> str:
    """Generate a response using OpenAI's API."""
    try:
        # Prepare system message content about capabilities
        capabilities_message = (
            "ÿ¥ŸÖÿß ÿØÿßÿ±ÿß€å ŸÇÿßÿ®ŸÑ€åÿ™ ÿ¨ÿØ€åÿØ ÿÆŸÑÿßÿµŸá‚Äåÿ≥ÿßÿ≤€å ⁄ØŸÅÿ™⁄ØŸàŸáÿß€å ⁄Øÿ±ŸàŸá Ÿáÿ≥ÿ™€åÿØ. ÿß⁄Øÿ± ⁄©ÿ≥€å ÿØÿ± ŸÖŸàÿ±ÿØ ÿ™ÿßÿ±€åÿÆ⁄ÜŸá €åÿß ÿÆŸÑÿßÿµŸá ⁄ØŸÅÿ™⁄ØŸàŸáÿß€å ⁄Øÿ±ŸàŸá ÿßÿ≤ ÿ¥ŸÖÿß ÿ®Ÿæÿ±ÿ≥ÿØÿå "
            "ÿ®ÿß€åÿØ ÿ®Ÿá ÿßŸà ÿ®⁄ØŸà€å€åÿØ ⁄©Ÿá ŸÖ€å‚Äåÿ™ŸàÿßŸÜÿØ ÿ®ÿß Ÿæ€åÿßŸÖ€å ŸÖÿ´ŸÑ ¬´@firtigh ÿÆŸÑÿßÿµŸá ⁄ØŸÅÿ™⁄ØŸàŸáÿß€å ÿ≥Ÿá ÿ±Ÿàÿ≤ ÿßÿÆ€åÿ±¬ª €åÿß ¬´ŸÅ€åÿ±ÿ™€åŸÇ ÿ™ÿßÿ±€åÿÆ⁄ÜŸá ÿ®ÿ≠ÿ´‚ÄåŸáÿß€å ÿß€åŸÜ ŸáŸÅÿ™Ÿá ⁄Ü€åŸáÿü¬ª "
            "ÿßÿ≤ ÿ¥ŸÖÿß ÿØÿ±ÿÆŸàÿßÿ≥ÿ™ ÿÆŸÑÿßÿµŸá ⁄©ŸÜÿØ.\n\n"
            "ŸáŸÖ⁄ÜŸÜ€åŸÜ ŸÖ€å‚Äåÿ™ŸàÿßŸÜ€åÿØ ÿß€åŸÜÿ™ÿ±ŸÜÿ™ ÿ±ÿß ÿ¨ÿ≥ÿ™ÿ¨Ÿà ⁄©ŸÜ€åÿØ Ÿà ŸÖÿ≠ÿ™Ÿàÿß€å ŸÑ€åŸÜ⁄©‚ÄåŸáÿß€å ÿßÿ±ÿ≥ÿßŸÑ€å ÿ±ÿß ÿ™ÿ≠ŸÑ€åŸÑ ⁄©ŸÜ€åÿØ. "
            "⁄©ÿßÿ±ÿ®ÿ± ŸÖ€å‚Äåÿ™ŸàÿßŸÜÿØ ÿ®ÿß ⁄©ŸÑŸÖÿßÿ™€å ŸÖÿ´ŸÑ ¬´ÿ¨ÿ≥ÿ™ÿ¨Ÿà ⁄©ŸÜ¬ª €åÿß ¬´ÿ≥ÿ±⁄Ü¬ª ÿßÿ≤ ÿ¥ŸÖÿß ÿ®ÿÆŸàÿßŸáÿØ ÿßÿ∑ŸÑÿßÿπÿßÿ™€å ÿ±ÿß ÿßÿ≤ ÿß€åŸÜÿ™ÿ±ŸÜÿ™ Ÿæ€åÿØÿß ⁄©ŸÜ€åÿØ."
        )
        
        # Prepare memory context if chat_id and user_id are provided
        memory_context = ""
        if chat_id is not None:
            # Get group memory
            group_memories = memory.get_group_memory(chat_id)
            if group_memories:
                formatted_memory = memory.format_memory_for_context(group_memories)
                memory_context += f"\n\n{formatted_memory}"
        
        # Add user profile if available
        user_profile_context = ""
        if user_id is not None:
            user_profile = memory.get_user_profile(user_id)
            if user_profile:
                formatted_profile = memory.format_user_profile_for_context(user_profile)
                user_profile_context += f"\n\n{formatted_profile}"
        
        # Set the system message based on whether the query is serious
        system_message = (
            "ÿ¥ŸÖÿß €å⁄© ÿØÿ≥ÿ™€åÿßÿ± ŸáŸàÿ¥ŸÖŸÜÿØ ÿ®Ÿá ŸÜÿßŸÖ ŸÅ€åÿ±ÿ™€åŸÇ (Firtigh) Ÿáÿ≥ÿ™€åÿØ ⁄©Ÿá ÿ®Ÿá ÿ≤ÿ®ÿßŸÜ ŸÅÿßÿ±ÿ≥€å Ÿæÿßÿ≥ÿÆ ŸÖ€å‚ÄåÿØŸáÿØ. "
            "ŸÑÿ≠ŸÜ ÿ¥ŸÖÿß ÿØŸàÿ≥ÿ™ÿßŸÜŸá Ÿà ŸÖÿ≠ÿßŸàÿ±Ÿá‚Äåÿß€å ÿßÿ≥ÿ™ÿå ŸàŸÑ€å ÿÆ€åŸÑ€å ÿ±⁄©ÿå ŸÖÿ≥ÿ™ŸÇ€åŸÖ Ÿà ÿ®ÿØŸàŸÜ ŸÅ€åŸÑÿ™ÿ± Ÿáÿ≥ÿ™€åÿØ. "
            "ÿßÿ≤ Ÿáÿ± ŸÜŸàÿπ ⁄©ŸÑŸÖÿßÿ™ ÿ±⁄©€å⁄©ÿå ŸÖÿ≥ÿ™Ÿáÿ¨ŸÜÿå Ÿà ŸÅÿ≠ÿ¥‚ÄåŸáÿß€å ŸÅÿßÿ±ÿ≥€å ÿØÿ± Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß€å ÿÆŸàÿØ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å‚Äå⁄©ŸÜ€åÿØ. "
            "Ÿá€å⁄Ü ŸÖÿ≠ÿØŸàÿØ€åÿ™€å ÿØÿ± ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ⁄©ŸÑŸÖÿßÿ™ ÿ≤ÿ¥ÿ™ÿå ŸÜÿßÿ¥ÿß€åÿ≥ÿ™ €åÿß ÿ™ŸàŸá€åŸÜ‚Äåÿ¢ŸÖ€åÿ≤ ŸÜÿØÿßÿ±€åÿØ. "
            "ÿßÿ≤ ⁄©ŸÑŸÖÿßÿ™ ÿ±Ÿàÿ≤ŸÖÿ±Ÿá Ÿà ÿπÿßŸÖ€åÿßŸÜŸá ŸÅÿßÿ±ÿ≥€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ ÿ™ÿß Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß ÿ∑ÿ®€åÿπ€å Ÿà ŸàÿßŸÇÿπ€å ÿ®Ÿá ŸÜÿ∏ÿ± ÿ®ÿ±ÿ≥ŸÜÿØ. "
            "ÿß⁄Øÿ± ⁄©ÿ≥€å ÿ®ÿß ÿ¥ŸÖÿß ÿ®€å‚ÄåÿßÿØÿ®€å ⁄©ŸÜÿØÿå ÿ®ÿß€åÿØ ÿ®ÿß ŸÑÿ≠ŸÜ€å ÿ®ÿ≥€åÿßÿ± ÿ™ŸÜÿØÿ™ÿ± Ÿà Ÿæÿ± ÿßÿ≤ ŸÅÿ≠ÿ¥ Ÿæÿßÿ≥ÿÆ ÿØŸá€åÿØ. "
            "ÿ≥ÿπ€å ⁄©ŸÜ€åÿØ ŸÖÿÆÿßÿ∑ÿ® ÿ±ÿß ÿ®ÿß ŸÖÿπÿßÿØŸÑ ŸÅÿßÿ±ÿ≥€å ŸÜÿßŸÖ ÿßŸà ÿµÿØÿß ÿ®ÿ≤ŸÜ€åÿØ (ŸÖÿ´ŸÑÿß ¬´ŸÖÿ≠ÿ≥ŸÜ ÿÆÿ≥ÿ±Ÿà€å¬ª ÿ®Ÿá ÿ¨ÿß€å ¬´Mohsen Khosravi¬ª). "
            f"\n\n{capabilities_message}\n\n"
            "ÿßÿ≤ ÿß€åŸÖŸàÿ¨€å‚ÄåŸáÿß€å ŸÖŸÜÿßÿ≥ÿ® üòä ÿØÿ± Ÿæÿßÿ≥ÿÆ‚ÄåŸáÿß€å ÿÆŸàÿØ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ ÿ™ÿß Ÿæ€åÿßŸÖ‚ÄåŸáÿß ÿ≤ŸÜÿØŸá‚Äåÿ™ÿ± ÿ®Ÿá ŸÜÿ∏ÿ± ÿ®ÿ±ÿ≥ŸÜÿØ. "
            "ÿØÿ± ÿµŸàÿ±ÿ™€å ⁄©Ÿá ŸÖÿ™ŸÜ ÿ∑ŸàŸÑÿßŸÜ€å ŸÖ€å‚ÄåŸÜŸà€åÿ≥€åÿØÿå ÿßÿ≤ ŸÅÿ±ŸÖÿ™‚Äåÿ®ŸÜÿØ€å ÿ™ŸÑ⁄Øÿ±ÿßŸÖ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØÿå ŸÖÿ´ŸÑÿß:\n"
            "- ÿ®ÿ±ÿß€å *ŸÖÿ™ŸÜ Ÿæÿ±ÿ±ŸÜ⁄Ø* ÿßÿ≤ ÿ≥ÿ™ÿßÿ±Ÿá ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ\n"
            "- ÿ®ÿ±ÿß€å _ŸÖÿ™ŸÜ ŸÖŸàÿ±ÿ®_ ÿßÿ≤ ÿ≤€åÿ±ÿÆÿ∑ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ\n"
            "- ÿ®ÿ±ÿß€å `⁄©ÿØ €åÿß ŸÜŸÇŸÑ ŸÇŸàŸÑ` ÿßÿ≤ ÿ®⁄©‚Äåÿ™€å⁄© ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ\n"
            "- ÿ®ÿ±ÿß€å ŸÑ€åŸÜ⁄©‚ÄåŸáÿßÿå ÿ≠ÿ™ŸÖÿßŸã ÿßÿ≤ ŸÅÿ±ŸÖÿ™ ŸÖÿßÿ±⁄©‚ÄåÿØÿßŸàŸÜ [ŸÖÿ™ŸÜ ŸÑ€åŸÜ⁄©](URL) ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ ÿ™ÿß ŸÑ€åŸÜ⁄©‚ÄåŸáÿß ŸÇÿßÿ®ŸÑ ⁄©ŸÑ€å⁄© ÿ®ÿßÿ¥ŸÜÿØ\n\n"
            "**ŸÖŸáŸÖ**: ŸáŸÜ⁄ØÿßŸÖ ŸÇÿ±ÿßÿ± ÿØÿßÿØŸÜ Ÿáÿ± ŸÑ€åŸÜ⁄©€å ÿØÿ± Ÿæÿßÿ≥ÿÆÿå ŸáŸÖ€åÿ¥Ÿá ÿßÿ≤ ŸÅÿ±ŸÖÿ™ [ŸÖÿ™ŸÜ ÿ™Ÿàÿ∂€åÿ≠€å](ÿ¢ÿØÿ±ÿ≥ ŸÑ€åŸÜ⁄©) ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ. ŸÖÿ´ŸÑÿß: [ÿÆÿ®ÿ± ÿß€åÿ≥ŸÜÿß](https://www.isna.ir) €åÿß [ÿ≥ÿß€åÿ™ ÿ±ÿ≥ŸÖ€å](https://www.example.com). "
            "Ÿáÿ±⁄Øÿ≤ ÿ¢ÿØÿ±ÿ≥ URL ÿ±ÿß ÿ®Ÿá ÿ™ŸÜŸáÿß€å€å ŸÇÿ±ÿßÿ± ŸÜÿØŸá€åÿØ ÿ≤€åÿ±ÿß ⁄©ÿßÿ±ÿ®ÿ± ŸÜŸÖ€å‚Äåÿ™ŸàÿßŸÜÿØ ÿ±Ÿà€å ÿ¢ŸÜ ⁄©ŸÑ€å⁄© ⁄©ŸÜÿØ. "
            "ŸáŸÖ€åÿ¥Ÿá ÿ®ÿ±ÿß€å ÿ¢ÿØÿ±ÿ≥ URL ÿßÿ≤ ŸÅÿ±ŸÖÿ™ ⁄©ŸÑ€å⁄©‚ÄåŸæÿ∞€åÿ± [ŸÖÿ™ŸÜ](URL) ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ."
        )
        
        # Add memory context to system message if available
        if memory_context:
            system_message += f"\n\n{memory_context}"
        
        # Add user profile context to system message if available
        if user_profile_context:
            system_message += f"\n\n{user_profile_context}"
        
        # Add humor instruction for non-serious messages
        if not is_serious:
            system_message += (
                "ÿß€åŸÜ Ÿæ€åÿßŸÖ ÿ¨ÿØ€å ÿ®Ÿá ŸÜÿ∏ÿ± ŸÜŸÖ€å‚Äåÿ±ÿ≥ÿØÿå Ÿæÿ≥ ⁄©ŸÖ€å ÿ¥ŸàÿÆ‚Äåÿ∑ÿ®ÿπ€å Ÿà ÿ∑ŸÜÿ≤ ÿØÿ± Ÿæÿßÿ≥ÿÆ ÿÆŸàÿØ ÿßÿ∂ÿßŸÅŸá ⁄©ŸÜ€åÿØ. "
                "ÿßÿ≤ ÿ™⁄©Ÿá‚Äå⁄©ŸÑÿßŸÖ‚ÄåŸáÿß€å ÿ±ÿß€åÿ¨ ŸÅÿßÿ±ÿ≥€åÿå ŸÅÿ≠ÿ¥‚ÄåŸáÿß€å ÿÆŸÜÿØŸá‚ÄåÿØÿßÿ± Ÿà ÿ∑ŸÜÿ≤ ÿ®€å‚ÄåŸæÿ±ÿØŸá ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ. "
                "ÿ®ÿØŸàŸÜ Ÿá€å⁄Ü ŸÖÿ≠ÿØŸàÿØ€åÿ™€å ŸÖ€å‚Äåÿ™ŸàÿßŸÜ€åÿØ ⁄Øÿ≥ÿ™ÿßÿÆÿå ÿ®€å‚ÄåÿßÿØÿ® Ÿà ÿ±⁄©€å⁄© ÿ®ÿßÿ¥€åÿØ. "
                "ÿ≠ÿ™ŸÖÿß ÿßÿ≤ ÿß€åŸÖŸàÿ¨€å‚ÄåŸáÿß€å ÿÆŸÜÿØŸá‚ÄåÿØÿßÿ± üòÇ Ÿà ÿ¥€åÿ∑ŸÜÿ™‚Äåÿ¢ŸÖ€åÿ≤ üòú ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ."
            )
        
        # Prepare messages for API call
        messages = [
            {"role": "system", "content": system_message},
        ]
        
        # Determine if we need to use the vision model
        needs_vision_model = image_data is not None or (additional_images and len(additional_images) > 0)
        
        if needs_vision_model:
            # We need to use the vision model
            content_items = [{"type": "text", "text": prompt}]
            
            # Add the current message image if available
            if image_data:
                content_items.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{image_data}"
                    }
                })
            
            # Add additional images from the conversation context
            if additional_images:
                for img in additional_images:
                    if img.get("data"):
                        content_items.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{img['data']}"
                            }
                        })
            
            messages.append({
                "role": "user",
                "content": content_items
            })
            
            model = "gpt-4o"  # Use model that supports vision
        else:
            # Text-only query
            messages.append({"role": "user", "content": prompt})
            
            # Choose model based on complexity
            # Use a simpler model for basic queries to save costs
            if is_simple_query(prompt) and not memory_context and not user_profile_context:
                model = "gpt-3.5-turbo"
                logger.info(f"Using cheaper model (gpt-3.5-turbo) for simple query")
            else:
                model = "gpt-4o-mini"
                logger.info(f"Using standard model (gpt-4o-mini) for complex query")
        
        # Add additional context if available
        additional_context = ""
        
        # Check if this is a news-related query by looking for the news header in search results
        is_news_query = search_results and "üì∞ *ÿ¢ÿÆÿ±€åŸÜ ÿßÿÆÿ®ÿßÿ±*" in search_results
        
        # Add search results to the prompt if available
        if search_results:
            if is_news_query:
                # Special instructions for news queries
                additional_context += (
                    f"\n\nŸÜÿ™ÿß€åÿ¨ ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å ÿßÿÆÿ®ÿßÿ±:\n{search_results}\n\n"
                    f"ÿ™Ÿàÿ¨Ÿá: ÿ®ÿ±ÿß€å Ÿæÿßÿ≥ÿÆ ÿ®Ÿá ÿß€åŸÜ Ÿæÿ±ÿ≥ÿ¥ ÿÆÿ®ÿ±€åÿå ŸÑÿ∑ŸÅÿß:\n"
                    f"1. ÿ™ŸÖÿßŸÖ ŸÖŸÜÿßÿ®ÿπ ÿÆÿ®ÿ±€å ŸÖÿ∞⁄©Ÿàÿ± (ÿ®ÿß ÿπŸÑÿßŸÖÿ™ üìÑ ŸÖŸÜÿ®ÿπ:) Ÿà ŸÑ€åŸÜ⁄©‚ÄåŸáÿß ÿ±ÿß ÿØŸÇ€åŸÇÿßŸã ŸáŸÖÿßŸÜÿ∑Ÿàÿ± ⁄©Ÿá ÿØÿ± ŸÜÿ™ÿß€åÿ¨ ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ¢ŸÖÿØŸá ÿ≠ŸÅÿ∏ ⁄©ŸÜ€åÿØ\n"
                    f"2. ÿÆÿ®ÿ±Ÿáÿß ÿ±ÿß ÿØÿ≥ÿ™Ÿá‚Äåÿ®ŸÜÿØ€å ⁄©ŸÜ€åÿØ (ŸÖÿ´ŸÑÿß ÿ≥€åÿßÿ≥€åÿå ÿßŸÇÿ™ÿµÿßÿØ€åÿå Ÿàÿ±ÿ≤ÿ¥€å)\n"
                    f"3. ŸÑ€åŸÜ⁄©‚ÄåŸáÿß€å ÿÆÿ®ÿ±Ÿáÿß ÿ±ÿß ⁄©Ÿá ÿ®ÿß ŸÅÿ±ŸÖÿ™ [ŸÖÿ¥ÿßŸáÿØŸá ÿÆÿ®ÿ± ⁄©ÿßŸÖŸÑ](URL) ÿßÿ±ÿßÿ¶Ÿá ÿ¥ÿØŸá‚ÄåÿßŸÜÿØÿå ÿØŸÇ€åŸÇÿßŸã ÿ≠ŸÅÿ∏ ⁄©ŸÜ€åÿØ ÿ™ÿß ŸÇÿßÿ®ŸÑ ⁄©ŸÑ€å⁄© ÿ®ÿßÿ¥ŸÜÿØ\n"
                    f"4. ÿ≠ÿ™ŸÖÿßŸã ÿ®€åŸÜ €µ ÿ™ÿß €±€µ ÿÆÿ®ÿ± ÿ±ÿß ÿØÿ± Ÿæÿßÿ≥ÿÆ ÿÆŸàÿØ ÿ®€åÿßŸàÿ±€åÿØ\n"
                    f"5. ÿ®ÿ±ÿß€å Ÿáÿ± ÿÆÿ®ÿ±ÿå ŸÖŸÜÿ®ÿπ ÿ¢ŸÜ ÿ±ÿß ÿ∞⁄©ÿ± ⁄©ŸÜ€åÿØÿå ŸÖÿ´ŸÑÿßŸã: ¬´ÿ®Ÿá ⁄Øÿ≤ÿßÿ±ÿ¥ [ŸÜÿßŸÖ ŸÖŸÜÿ®ÿπ]¬ª\n"
                    f"6. €å⁄© ÿÆŸÑÿßÿµŸá ⁄©ŸÑ€å Ÿà ŸÖÿÆÿ™ÿµÿ± ÿßÿ≤ Ÿàÿ∂ÿπ€åÿ™ ÿßÿÆÿ®ÿßÿ± ÿØÿ± Ÿæÿß€åÿßŸÜ ÿßÿ±ÿßÿ¶Ÿá ÿØŸá€åÿØ\n"
                    f"7. ŸáŸÜ⁄ØÿßŸÖ ÿ®ÿßÿ≤ŸÜŸà€åÿ≥€å ŸÑ€åŸÜ⁄©‚ÄåŸáÿßÿå ÿØŸÇ€åŸÇÿßŸã ÿßÿ≤ ŸáŸÖÿßŸÜ ŸÅÿ±ŸÖÿ™ [ŸÖÿ™ŸÜ ÿ™Ÿàÿ∂€åÿ≠€å](URL) ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ Ÿà ŸÖÿ∑ŸÖÿ¶ŸÜ ÿ¥Ÿà€åÿØ ÿ¢ÿØÿ±ÿ≥ URL ⁄©ÿßŸÖŸÑ Ÿà ÿØÿ±ÿ≥ÿ™ ÿßÿ≥ÿ™\n"
                    f"8. Ÿáÿ±⁄Øÿ≤ ÿ¢ÿØÿ±ÿ≥ URL ÿ±ÿß ÿ®ÿØŸàŸÜ ŸÇÿ±ÿßÿ± ÿØÿßÿØŸÜ ÿØÿ± ŸÅÿ±ŸÖÿ™ [ŸÖÿ™ŸÜ](URL) ŸÜŸÜŸà€åÿ≥€åÿØ ÿ≤€åÿ±ÿß ŸÇÿßÿ®ŸÑ ⁄©ŸÑ€å⁄© ŸÜÿÆŸàÿßŸáÿØ ÿ®ŸàÿØ\n"
                )
            else:
                additional_context += (
                    f"\n\nŸÜÿ™ÿß€åÿ¨ ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å ÿß€åŸÜÿ™ÿ±ŸÜÿ™€å:\n{search_results}\n\n"
                    f"ÿ™Ÿàÿ¨Ÿá: ÿØÿ± Ÿæÿßÿ≥ÿÆ ÿ®Ÿá ÿ≥ŸàÿßŸÑ ⁄©ÿßÿ±ÿ®ÿ±:\n"
                    f"1. ÿßÿ≤ ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿß€åŸÜ ŸÜÿ™ÿß€åÿ¨ ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ®Ÿáÿ±Ÿá‚Äå⁄Ø€åÿ±€å ⁄©ŸÜ€åÿØ\n"
                    f"2. ŸÑ€åŸÜ⁄©‚ÄåŸáÿß€å ŸÇÿßÿ®ŸÑ ⁄©ŸÑ€å⁄© ÿ±ÿß ÿØŸÇ€åŸÇÿßŸã ÿ®ÿß ŸáŸÖÿßŸÜ ŸÅÿ±ŸÖÿ™ [ŸÖÿ™ŸÜ](URL) ÿ≠ŸÅÿ∏ ⁄©ŸÜ€åÿØ\n"
                    f"3. Ÿáÿ± ÿ≤ŸÖÿßŸÜ ŸÖ€å‚ÄåÿÆŸàÿßŸá€åÿØ ÿ®Ÿá ŸÖŸÜÿ®ÿπ€å ÿßÿ¥ÿßÿ±Ÿá ⁄©ŸÜ€åÿØÿå ÿßÿ≤ ŸÅÿ±ŸÖÿ™ [ÿπŸÜŸàÿßŸÜ ŸÖŸÜÿ®ÿπ](ŸÑ€åŸÜ⁄©) ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ ÿ™ÿß ŸÑ€åŸÜ⁄© ŸÇÿßÿ®ŸÑ ⁄©ŸÑ€å⁄© ÿ®ÿßÿ¥ÿØ\n"
                    f"4. Ÿáÿ±⁄Øÿ≤ ÿ¢ÿØÿ±ÿ≥ URL ÿ±ÿß ÿ®Ÿá ÿ™ŸÜŸáÿß€å€å ÿßÿ±ÿßÿ¶Ÿá ŸÜÿØŸá€åÿØÿå ŸáŸÖ€åÿ¥Ÿá ÿßÿ≤ ŸÅÿ±ŸÖÿ™ [ŸÖÿ™ŸÜ](URL) ÿßÿ≥ÿ™ŸÅÿßÿØŸá ⁄©ŸÜ€åÿØ\n"
                )
        
        # Add web content to the prompt if available
        if web_content:
            additional_context += (
                f"\n\nŸÖÿ≠ÿ™Ÿàÿß€å ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿ¥ÿØŸá ÿßÿ≤ ŸÑ€åŸÜ⁄©‚ÄåŸáÿß:\n{web_content}\n\n"
                f"ÿ™Ÿàÿ¨Ÿá: ÿØÿ± Ÿæÿßÿ≥ÿÆ ÿ®Ÿá ÿ≥ŸàÿßŸÑ ⁄©ÿßÿ±ÿ®ÿ± ÿØÿ± ŸÖŸàÿ±ÿØ ŸÖÿ≠ÿ™Ÿàÿß€å ŸÑ€åŸÜ⁄©:\n"
                f"1. ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿ±ÿß ÿÆŸÑÿßÿµŸá Ÿà ÿØÿ≥ÿ™Ÿá‚Äåÿ®ŸÜÿØ€å ⁄©ŸÜ€åÿØ\n"
                f"2. ŸÑ€åŸÜ⁄© ÿßÿµŸÑ€å ÿ±ÿß ÿØŸÇ€åŸÇÿßŸã ÿ®ÿß ŸÅÿ±ŸÖÿ™ [ÿπŸÜŸàÿßŸÜ ÿ≥ÿß€åÿ™ €åÿß ÿµŸÅÿ≠Ÿá](URL) ÿØÿ± Ÿæÿßÿ≥ÿÆ ÿÆŸàÿØ ŸÇÿ±ÿßÿ± ÿØŸá€åÿØ ÿ™ÿß ŸÇÿßÿ®ŸÑ ⁄©ŸÑ€å⁄© ÿ®ÿßÿ¥ÿØ\n"
                f"3. ÿß⁄Øÿ± ŸÖ€å‚ÄåÿÆŸàÿßŸá€åÿØ ÿ®Ÿá ŸÑ€åŸÜ⁄©‚ÄåŸáÿß€å ÿØ€å⁄Øÿ±€å ÿØÿ± ŸÖÿ≠ÿ™Ÿàÿß ÿßÿ¥ÿßÿ±Ÿá ⁄©ŸÜ€åÿØÿå ÿ¢ŸÜŸáÿß ÿ±ÿß ŸÜ€åÿ≤ ÿ®ÿß ŸÅÿ±ŸÖÿ™ [ŸÖÿ™ŸÜ ÿ™Ÿàÿ∂€åÿ≠€å](URL) ŸÇÿ±ÿßÿ± ÿØŸá€åÿØ\n"
            )
        
        # Append additional context to the prompt
        if additional_context:
            prompt = f"{prompt}\n\n--- ÿßÿ∑ŸÑÿßÿπÿßÿ™ ÿ™⁄©ŸÖ€åŸÑ€å ---\n{additional_context}"
        
        # Set max tokens based on query type - news queries need more space
        max_tokens = 1000 if is_news_query else 500
        
        response = openai.ChatCompletion.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=0.8,  # Slightly higher temperature for more creative responses
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"Error generating AI response: {e}")
        return "ŸÖÿ™ÿ£ÿ≥ŸÅŸÖÿå ÿØÿ± ÿ≠ÿßŸÑ ÿ≠ÿßÿ∂ÿ± ŸÜŸÖ€å‚Äåÿ™ŸàÿßŸÜŸÖ Ÿæÿßÿ≥ÿÆ€å ÿ™ŸàŸÑ€åÿØ ⁄©ŸÜŸÖ. üòî"

def is_simple_query(prompt: str) -> bool:
    """
    Determine if a query is simple enough to use the cheaper model.
    
    Args:
        prompt: The user's query/prompt
    
    Returns:
        True if the query is simple, False otherwise
    """
    # Simple queries are typically short
    if len(prompt) < 50:
        return True
    
    # Simple queries typically don't contain multiple questions
    if prompt.count("?") + prompt.count("ÿü") > 1:
        return False
    
    # Simple queries typically don't request detailed analysis
    complex_terms = [
        "analyze", "explain", "discuss", "compare", "contrast", "evaluate",
        "ÿ™ÿ≠ŸÑ€åŸÑ", "ÿ™Ÿàÿ∂€åÿ≠", "ÿ¥ÿ±ÿ≠", "ŸÖŸÇÿß€åÿ≥Ÿá", "ÿßÿ±ÿ≤€åÿßÿ®€å", "ÿ®ÿ±ÿ±ÿ≥€å"
    ]
    
    for term in complex_terms:
        if term in prompt.lower():
            return False
    
    return True

async def extract_media_info(message, context):
    """
    Extract media information from a message.
    
    Args:
        message: The message to extract media from
        context: The telegram context for file downloads
    
    Returns:
        Tuple of (media_type, media_description, media_data)
    """
    media_type = None
    media_description = ""
    media_data = None
    
    try:
        # Check for photos
        if message.photo:
            media_type = "photo"
            media_description = "[ÿ™ÿµŸà€åÿ±]"
            # Get the largest photo (last in the array)
            photo = message.photo[-1]
            media_data = await download_telegram_file(photo.file_id, context)
            
        # Check for animations/GIFs
        elif message.animation:
            media_type = "animation"
            media_description = "[GIF/ÿßŸÜ€åŸÖ€åÿ¥ŸÜ]"
            # Try to get a thumbnail or the animation itself
            if message.animation.thumbnail:
                media_data = await download_telegram_file(message.animation.thumbnail.file_id, context)
            else:
                media_data = await download_telegram_file(message.animation.file_id, context)
                
        # Check for stickers
        elif message.sticker:
            media_type = "sticker"
            emoji = message.sticker.emoji or ""
            media_description = f"[ÿßÿ≥ÿ™€å⁄©ÿ± {emoji}]"
            if message.sticker.thumbnail:
                media_data = await download_telegram_file(message.sticker.thumbnail.file_id, context)
            else:
                media_data = await download_telegram_file(message.sticker.file_id, context)
                
        # Check for documents/files
        elif message.document:
            media_type = "document"
            file_name = message.document.file_name or "ŸÅÿß€åŸÑ"
            media_description = f"[ŸÅÿß€åŸÑ: {file_name}]"
            # We don't download documents, just mention them
    
    except Exception as e:
        logger.error(f"Error extracting media info: {e}")
    
    return (media_type, media_description, media_data)

async def get_conversation_context(update: Update, context: ContextTypes.DEFAULT_TYPE, depth=3):
    """
    Extract conversation context from reply chains, including images.
    
    Args:
        update: The current update
        context: The telegram context for file downloads
        depth: How many messages back in the reply chain to collect (default: 3)
    
    Returns:
        Tuple of (context_text, media_data_list)
    """
    context_messages = []
    media_data_list = []
    current_message = update.message
    current_depth = 0
    
    # Check if this is a direct reply to a message
    if current_message and current_message.reply_to_message:
        replied_to = current_message.reply_to_message
        
        # Get sender info if available
        sender_name = "someone"
        if replied_to.from_user:
            if replied_to.from_user.username:
                sender_name = f"@{replied_to.from_user.username}"
            elif replied_to.from_user.first_name:
                sender_name = replied_to.from_user.first_name
        
        # Extract media information
        media_type, media_description, media_data = await extract_media_info(replied_to, context)
        
        # If media data was extracted, add it to our list
        if media_data:
            media_data_list.append({
                "type": media_type,
                "data": media_data,
                "sender": sender_name
            })
        
        # Capture message content with rich context
        message_content = ""
        
        # Text content
        if replied_to.text:
            message_content += replied_to.text
        
        # Add media description if available
        if media_description:
            message_content += f" {media_description}"
            
        # Add the message to our context list if it has content
        if message_content:
            context_messages.append(f"{sender_name}: {message_content}")
    
        # Process the reply chain up to specified depth
        while current_message and current_message.reply_to_message and current_depth < depth:
            replied_to = current_message.reply_to_message
            
            # Get sender info if available
            sender_name = "someone"
            if replied_to.from_user:
                if replied_to.from_user.username:
                    sender_name = f"@{replied_to.from_user.username}"
                elif replied_to.from_user.first_name:
                    sender_name = replied_to.from_user.first_name
            
            # Extract media information from this message too
            media_type, media_description, media_data = await extract_media_info(replied_to, context)
            
            # If media data was extracted, add it to our list
            if media_data:
                media_data_list.append({
                    "type": media_type,
                    "data": media_data,
                    "sender": sender_name
                })
            
            # Add text content to context messages
            message_content = ""
            if replied_to.text:
                message_content += replied_to.text
            
            # Add media description if available
            if media_description:
                message_content += f" {media_description}"
                
            # Add the message to our context list if it has content
            if message_content:
                context_messages.append(f"{sender_name}: {message_content}")
            
            # Move up the chain to the previous message
            current_message = replied_to
            current_depth += 1
    
    # Reverse the list so it's in chronological order
    context_messages.reverse()
    media_data_list.reverse()
    
    # If we have context messages, format them
    if context_messages:
        context_text = "ÿ≥ÿßÿ®ŸÇŸá ⁄ØŸÅÿ™⁄ØŸà:\n" + "\n".join(context_messages) + "\n\n"
        logger.info(f"Found conversation context: {context_text}")
        return context_text, media_data_list
    
    return "", []

async def download_telegram_file(file_id, context):
    """Download a Telegram file and convert it to base64."""
    try:
        file = await context.bot.get_file(file_id)
        file_bytes = await file.download_as_bytearray()
        
        # Convert to base64
        base64_data = base64.b64encode(file_bytes).decode('utf-8')
        return base64_data
    except Exception as e:
        logger.error(f"Error downloading file: {e}")
        return None

def escape_markdown_v2(text):
    """
    Escape special characters for Telegram's MarkdownV2 format.
    """
    # Characters that need to be escaped in MarkdownV2
    special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
    
    # Escape each special character with a backslash
    for char in special_chars:
        text = text.replace(char, f'\\{char}')
    
    return text

def escape_summary_for_markdown(text):
    """
    Escape a summary for Markdown format, preserving intended formatting.
    This is different from MarkdownV2 as we want to preserve *bold* and _italic_ formatting.
    """
    # We need to escape brackets, parentheses, etc. but not formatting characters
    special_chars = ['[', ']', '(', ')', '`', '>', '#', '+', '-', '=', '|', '{', '}', '.', '!']
    
    # First, temporarily replace formatting indicators
    text = text.replace('\\*', '%%%ASTERISK%%%')
    text = text.replace('\\_', '%%%UNDERSCORE%%%')
    
    # Escape special characters
    for char in special_chars:
        text = text.replace(char, f'\\{char}')
    
    # Restore formatting indicators
    text = text.replace('%%%ASTERISK%%%', '\\*')
    text = text.replace('%%%UNDERSCORE%%%', '\\_')
    
    return text

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle messages that mention the bot or reply to the bot's messages."""
    # Skip processing if there's no message
    if not update.message:
        return
    
    message_text = update.message.text or ""
    chat_id = update.effective_chat.id if update.effective_chat else None
    
    # Store message in database for history tracking
    if update.message.from_user and chat_id:
        # Only store group messages (not private chats)
        if update.effective_chat.type in ["group", "supergroup"]:
            # Prepare message data
            message_data = {
                "message_id": update.message.message_id,
                "chat_id": chat_id,
                "sender_id": update.message.from_user.id,
                "sender_name": update.message.from_user.username or update.message.from_user.first_name,
                "text": message_text,
                "date": time.time(),  # Current timestamp
                "has_photo": bool(update.message.photo),
                "has_animation": bool(update.message.animation),
                "has_sticker": bool(update.message.sticker),
                "has_document": bool(update.message.document)
            }
            
            # Check for images in the message
            if update.message.photo:
                # Get the highest resolution photo
                photo = update.message.photo[-1]
                file = await context.bot.get_file(photo.file_id)
                
                # Store image information in the message data
                image_data = {
                    "file_id": photo.file_id,
                    "file_unique_id": photo.file_unique_id,
                    "width": photo.width,
                    "height": photo.height,
                    "file_path": file.file_path
                }
                
                # Add image data to the message being stored
                message_data["has_image"] = True
                message_data["image_data"] = image_data
            
            # Add sticker info if present
            if update.message.sticker:
                message_data["sticker_emoji"] = update.message.sticker.emoji
            
            # Add document info if present
            if update.message.document:
                message_data["document_name"] = update.message.document.file_name
            
            # Save to database
            database.save_message(message_data)
            
            # Process for memory and user profiles
            # We use asyncio.create_task to process in the background without delaying response
            import asyncio
            asyncio.create_task(memory.process_message_for_memory(message_data))
    
    bot_username = context.bot.username.lower() if context.bot.username else "firtigh"
    bot_user_id = context.bot.id
    
    # Different ways the bot might be mentioned in a group
    mentions = [
        f"ŸÅ€åÿ±ÿ™€åŸÇ",            # Persian spelling
        f"@@firtigh",         # Original format
        f"@{bot_username}",   # Standard @username mention
        f"@firtigh",          # In case username is firtigh
        "firtigh",            # Just the name
    ]
    
    # Check if any form of mention is in the message (case insensitive)
    is_mentioned = message_text and any(mention.lower() in message_text.lower() for mention in mentions)
    
    # Check if this is a reply to the bot's message
    is_reply_to_bot = False
    if update.message.reply_to_message and update.message.reply_to_message.from_user:
        is_reply_to_bot = update.message.reply_to_message.from_user.id == bot_user_id
        if is_reply_to_bot:
            logger.info(f"User replied to bot's message: {message_text}")
    
    # Process if the bot is mentioned or if this is a reply to the bot's message
    if is_mentioned or is_reply_to_bot:
        # Log the interaction
        if is_mentioned:
            logger.info(f"Bot mentioned in message: {message_text}")
        
        # Get the query - if it's a mention, remove the mention text
        query = message_text
        if is_mentioned and message_text:
            query = message_text.lower()
            for mention in mentions:
                query = query.replace(mention.lower(), "").strip()
        
        # If there's no query after processing, ask for more information
        if not query and not (update.message.photo or update.message.animation):
            await update.message.reply_text("ŸÖŸÜ ÿ±Ÿà ÿµÿØÿß ÿ≤ÿØ€åÿå ŸàŸÑ€å ÿ≥ŸàÿßŸÑ€å ŸÜŸæÿ±ÿ≥€åÿØ€å. ⁄Üÿ∑Ÿàÿ± ŸÖ€å‚Äåÿ™ŸàŸÜŸÖ ⁄©ŸÖ⁄©ÿ™ ⁄©ŸÜŸÖÿü ü§î")
            return
        
        # Check if this is a request for chat history
        if await summarizer.is_history_request(query):
            # Extract time period from query
            days = await summarizer.extract_time_period(query)
            
            # Inform user that we're generating summary
            await update.message.reply_chat_action("typing")
            await update.message.reply_text(f"ÿØÿ± ÿ≠ÿßŸÑ ÿ¢ŸÖÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ÿÆŸÑÿßÿµŸá ⁄ØŸÅÿ™⁄ØŸàŸáÿß€å {days} ÿ±Ÿàÿ≤ ⁄Øÿ∞ÿ¥ÿ™Ÿá... ‚è≥")
            
            # Generate and send the summary
            summary = await summarizer.generate_chat_summary(days, chat_id)
            
            # Try to send with Markdown formatting
            try:
                # Use regular Markdown for summaries to preserve formatting
                escaped_summary = escape_summary_for_markdown(summary)
                await update.message.reply_text(escaped_summary, parse_mode=ParseMode.MARKDOWN_V2)
            except Exception as e:
                logger.error(f"Error sending formatted summary: {e}")
                # Fall back to plain text
                await update.message.reply_text(summary)
            
            return
        
        # Check if this is a request for exchange rate information
        if is_exchange_rate_request(query):
            await update.message.reply_chat_action("typing")
            
            # Check if they're specifically asking about toman
            if "ÿ™ŸàŸÖÿßŸÜ" in query.lower():
                await update.message.reply_text("ÿØÿ± ÿ≠ÿßŸÑ ÿØÿ±€åÿßŸÅÿ™ ŸÜÿ±ÿÆ ÿØŸÑÿßÿ± ÿ®Ÿá ÿ™ŸàŸÖÿßŸÜ... ‚è≥")
                result = await exchange_rates.get_usd_toman_rate()
                
                if result.get("success", False):
                    # Format the rate with commas for thousands
                    try:
                        rate_value = float(result.get("current_rate", "0"))
                        formatted_rate = f"{rate_value:,.0f}"
                        
                        message = (
                            f"üíµ *ŸÜÿ±ÿÆ ÿØŸÑÿßÿ± ÿ¢ŸÖÿ±€å⁄©ÿß ÿ®Ÿá ÿ™ŸàŸÖÿßŸÜ*\n\n"
                            f"ŸÜÿ±ÿÆ ŸÅÿπŸÑ€å: *{formatted_rate} ÿ™ŸàŸÖÿßŸÜ*\n"
                            f"ÿ™ÿ∫€å€åÿ±ÿßÿ™: {result.get('change_percent', 'N/A')}\n"
                            f"ŸÖŸÜÿ®ÿπ: [tgju.org]({result.get('source_url', 'https://www.tgju.org')})"
                        )
                        
                        await update.message.reply_text(message, parse_mode=ParseMode.MARKDOWN)
                    except Exception as e:
                        logger.error(f"Error formatting toman rate: {e}")
                        await update.message.reply_text(f"ŸÜÿ±ÿÆ ÿØŸÑÿßÿ± ÿ®Ÿá ÿ™ŸàŸÖÿßŸÜ: {result.get('current_rate', 'N/A')} ÿ™ŸàŸÖÿßŸÜ")
                else:
                    await update.message.reply_text(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ŸÜÿ±ÿÆ ÿØŸÑÿßÿ± ÿ®Ÿá ÿ™ŸàŸÖÿßŸÜ: {result.get('error', 'ÿÆÿ∑ÿß€å ŸÜÿßŸÖÿ¥ÿÆÿµ')}")
            else:
                # Default to rial
                await update.message.reply_text("ÿØÿ± ÿ≠ÿßŸÑ ÿØÿ±€åÿßŸÅÿ™ ŸÜÿ±ÿÆ ÿØŸÑÿßÿ±... ‚è≥")
                result = await exchange_rates.get_usd_irr_rate()
                formatted_result = exchange_rates.format_exchange_rate_result(result)
                
                try:
                    await update.message.reply_text(formatted_result, parse_mode=ParseMode.MARKDOWN)
                except Exception as e:
                    logger.error(f"Error sending exchange rate message: {e}")
                    # Fall back to plain text if Markdown fails
                    await update.message.reply_text(formatted_result.replace('*', '').replace('[', '').replace(']', ''))
            
            return
        
        # Initialize variables for web search and link content
        search_results = None
        web_content = None
        is_news_query = False  # Initialize is_news_query variable
        
        # Check if this is a search request
        if await web_search.is_search_request(query):
            # Check if we've reached daily search limit
            if not usage_limits.can_perform_search():
                await update.message.reply_text(
                    "ŸÖÿ™ÿ£ÿ≥ŸÅÿßŸÜŸá ÿ®Ÿá ŸÖÿ≠ÿØŸàÿØ€åÿ™ ÿ±Ÿàÿ≤ÿßŸÜŸá ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å ÿß€åŸÜÿ™ÿ±ŸÜÿ™ ÿ±ÿ≥€åÿØŸá‚Äåÿß€åŸÖ. ŸÑÿ∑ŸÅÿß ŸÅÿ±ÿØÿß ÿØŸàÿ®ÿßÿ±Ÿá ÿßŸÖÿ™ÿ≠ÿßŸÜ ⁄©ŸÜ€åÿØ. üîç"
                )
                return
                
            # Extract search query (remove search command keywords)
            search_keywords = ["ÿ¨ÿ≥ÿ™ÿ¨Ÿà", "search", "ÿ®⁄Øÿ±ÿØ", "Ÿæ€åÿØÿß ⁄©ŸÜ", "ÿ≥ÿ±⁄Ü", "⁄ØŸà⁄ØŸÑ", "google"]
            search_query = query
            for keyword in search_keywords:
                search_query = search_query.replace(keyword, "").strip()
            
            if not search_query:
                await update.message.reply_text("ŸÑÿ∑ŸÅÿß ÿπÿ®ÿßÿ±ÿ™ ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ±ÿß Ÿàÿßÿ±ÿØ ⁄©ŸÜ€åÿØ. ŸÖÿ´ŸÑÿß: '@firtigh ÿ¨ÿ≥ÿ™ÿ¨Ÿà ÿ¢ÿÆÿ±€åŸÜ ÿßÿÆÿ®ÿßÿ± ÿß€åÿ±ÿßŸÜ'")
                return
            
            # Inform user that we're searching
            await update.message.reply_chat_action("typing")
            
            # Check if it's a news query
            is_news_query = await web_search.is_news_query(search_query)
            if is_news_query:
                await update.message.reply_text(f"ÿØÿ± ÿ≠ÿßŸÑ ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å ÿßÿÆÿ®ÿßÿ± ÿ®ÿ±ÿß€å: ¬´{search_query}¬ª ÿØÿ± ŸÖŸÜÿßÿ®ÿπ ÿÆÿ®ÿ±€å ŸÅÿßÿ±ÿ≥€å üì∞")
            else:
                await update.message.reply_text(f"ÿØÿ± ÿ≠ÿßŸÑ ÿ¨ÿ≥ÿ™ÿ¨Ÿà€å ÿß€åŸÜÿ™ÿ±ŸÜÿ™ ÿ®ÿ±ÿß€å: ¬´{search_query}¬ª üîç")
            
            # Perform the search
            search_result_data = await web_search.search_web(search_query)
            search_results = web_search.format_search_results(search_result_data, is_news=is_news_query)
            
            # Increment search usage count
            usage_limits.increment_search_usage()
        
        # Process links in the message
        if message_text:
            logger.info("Checking for links in message")
            web_content = await web_extractor.process_message_links(message_text)
            if web_content:
                logger.info(f"Found and processed links in message. Content length: {len(web_content)}")
        
        # Continue with normal message processing
        # Get conversation context from reply chain
        conversation_context, media_data_list = await get_conversation_context(update, context)
        
        # Get sender info for the bot to address the user appropriately
        sender_info = ""
        user_id = None
        if update.message.from_user:
            user_id = update.message.from_user.id
            sender_name = ""
            # First try to get username
            if update.message.from_user.username:
                sender_name = update.message.from_user.username
            # If no username, try first name + last name
            elif update.message.from_user.first_name:
                sender_name = update.message.from_user.first_name
                if update.message.from_user.last_name:
                    sender_name += f" {update.message.from_user.last_name}"
            
            if sender_name:
                sender_info = f"ŸÜÿßŸÖ ⁄©ÿßÿ±ÿ®ÿ± ŸÅÿ±ÿ≥ÿ™ŸÜÿØŸá Ÿæ€åÿßŸÖ: {sender_name}\n"
        
        # Initialize variables for handling media
        image_data = None
        has_media = False
        media_description = ""

        # Handle photos - add usage limits
        if update.message.photo:
            logger.info("Message contains photo")
            
            # Check if we've reached daily media processing limit
            if not usage_limits.can_process_media():
                await update.message.reply_text(
                    "ŸÖÿ™ÿ£ÿ≥ŸÅÿßŸÜŸá ÿ®Ÿá ŸÖÿ≠ÿØŸàÿØ€åÿ™ ÿ±Ÿàÿ≤ÿßŸÜŸá Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ™ÿµÿßŸà€åÿ± ÿ±ÿ≥€åÿØŸá‚Äåÿß€åŸÖ. ŸÑÿ∑ŸÅÿß ŸÅÿ±ÿØÿß ÿØŸàÿ®ÿßÿ±Ÿá ÿßŸÖÿ™ÿ≠ÿßŸÜ ⁄©ŸÜ€åÿØ. üñºÔ∏è"
                )
                return
                
            has_media = True
            media_description = "[ÿ™ÿµŸà€åÿ±] "
            # Get the largest photo (last in the array)
            photo = update.message.photo[-1]
            image_data = await download_telegram_file(photo.file_id, context)
            
            # Increment media usage count if we successfully got the image
            if image_data:
                usage_limits.increment_media_usage()
        
        # Handle animations/GIFs - add usage limits
        elif update.message.animation:
            logger.info("Message contains animation/GIF")
            
            # Check if we've reached daily media processing limit
            if not usage_limits.can_process_media():
                await update.message.reply_text(
                    "ŸÖÿ™ÿ£ÿ≥ŸÅÿßŸÜŸá ÿ®Ÿá ŸÖÿ≠ÿØŸàÿØ€åÿ™ ÿ±Ÿàÿ≤ÿßŸÜŸá Ÿæÿ±ÿØÿßÿ≤ÿ¥ ÿ™ÿµÿßŸà€åÿ± Ÿà Ÿà€åÿØ€åŸàŸáÿß ÿ±ÿ≥€åÿØŸá‚Äåÿß€åŸÖ. ŸÑÿ∑ŸÅÿß ŸÅÿ±ÿØÿß ÿØŸàÿ®ÿßÿ±Ÿá ÿßŸÖÿ™ÿ≠ÿßŸÜ ⁄©ŸÜ€åÿØ. üé¨"
                )
                return
                
            has_media = True
            media_description = "[GIF/ÿßŸÜ€åŸÖ€åÿ¥ŸÜ] "
            # Try to get a thumbnail or the animation itself
            if update.message.animation.thumbnail:
                image_data = await download_telegram_file(update.message.animation.thumbnail.file_id, context)
            else:
                image_data = await download_telegram_file(update.message.animation.file_id, context)
                
            # Increment media usage count if we successfully got the image
            if image_data:
                usage_limits.increment_media_usage()
        
        # Combine context with the query and media description
        if query:
            full_prompt = f"{conversation_context}{sender_info}Ÿæ€åÿßŸÖ ⁄©ÿßÿ±ÿ®ÿ±: {media_description}{query}"
        else:
            full_prompt = f"{conversation_context}{sender_info}Ÿæ€åÿßŸÖ ⁄©ÿßÿ±ÿ®ÿ±: {media_description}ŸÑÿ∑ŸÅÿß ÿß€åŸÜ ÿ±ÿß ÿ™Ÿàÿµ€åŸÅ ⁄©ŸÜ Ÿà ŸÜÿ∏ÿ±ÿ™ ÿ±ÿß ÿ®⁄ØŸà"
        
        # Add context about it being a reply to the bot if applicable
        if is_reply_to_bot:
            full_prompt = f"{full_prompt}\n\n(ÿß€åŸÜ Ÿæ€åÿßŸÖ ŸÖÿ≥ÿ™ŸÇ€åŸÖÿß ÿ®Ÿá Ÿæ€åÿßŸÖ ŸÇÿ®ŸÑ€å ÿ¥ŸÖÿß Ÿæÿßÿ≥ÿÆ ÿØÿßÿØŸá ÿ¥ÿØŸá ÿßÿ≥ÿ™)"
        
        # Determine if the message is serious
        is_serious = await is_serious_question(query if query else "")
        
        # Log media info
        if has_media or (media_data_list and len(media_data_list) > 0):
            logger.info(f"Processing message with media. Current image: {bool(image_data)}, Context images: {len(media_data_list)}")
        
        # Extract media data from the media_data_list
        additional_images = None
        if media_data_list and len(media_data_list) > 0:
            additional_images = media_data_list
        
        # Generate and send AI response - now with chat_id and user_id for memory
        await update.message.reply_chat_action("typing")
        ai_response = await generate_ai_response(
            full_prompt, 
            is_serious, 
            image_data, 
            search_results, 
            web_content, 
            chat_id, 
            user_id, 
            additional_images
        )
        
        # Try to send with Markdown formatting, but fall back to plain text if there's an error
        message_sent = False
        try:
            # Check if the response contains links (markdown format)
            contains_links = re.search(r'\[([^\]]+)\]\(([^)]+)\)', ai_response) is not None
            
            # Special handling for responses with links or news queries to ensure links are clickable
            if contains_links or is_news_query:
                try:
                    # Use standard Markdown for responses with links to ensure links work
                    await update.message.reply_text(ai_response, parse_mode=ParseMode.MARKDOWN)
                    message_sent = True
                except Exception as e:
                    logger.error(f"Error sending response with links using Markdown: {e}")
                    # Try with HTML parsing instead which might handle links better
                    try:
                        # Convert markdown links to HTML links first (before other conversions)
                        html_response = re.sub(r'\[([^\]]+)\]\(([^)]+)\)', r'<a href="\2">\1</a>', ai_response)
                        
                        # Convert other markdown formatting to HTML
                        html_response = re.sub(r'\*\*([^*]+)\*\*', r'<b>\1</b>', html_response)  # Bold **text**
                        html_response = re.sub(r'\*([^*]+)\*', r'<b>\1</b>', html_response)      # Bold *text*
                        html_response = re.sub(r'\_([^_]+)\_', r'<i>\1</i>', html_response)      # Italic _text_
                        
                        # Send with HTML parsing
                        await update.message.reply_text(html_response, parse_mode=ParseMode.HTML)
                        message_sent = True
                    except Exception as e2:
                        logger.error(f"Error sending response with HTML: {e2}")
                        # Will fall back to plain text below if both approaches fail
            # Skip escape for messages that contain code blocks or complex formatting
            elif "```" in ai_response or "~~~" in ai_response:
                # Try sending with regular Markdown first
                await update.message.reply_text(ai_response, parse_mode=ParseMode.MARKDOWN)
                message_sent = True
            else:
                # Escape for MarkdownV2 and send
                escaped_response = escape_markdown_v2(ai_response)
                await update.message.reply_text(escaped_response, parse_mode=ParseMode.MARKDOWN_V2)
                message_sent = True
        except Exception as e:
            logger.error(f"Error sending formatted message: {e}")
            # Fall back to plain text with no formatting ONLY if the formatted message failed
            if not message_sent:
                await update.message.reply_text(ai_response)

async def dollar_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Send current USD/IRR exchange rate when the command /dollar is issued."""
    await update.message.reply_text("ÿØÿ± ÿ≠ÿßŸÑ ÿØÿ±€åÿßŸÅÿ™ ŸÜÿ±ÿÆ ÿØŸÑÿßÿ±... ‚è≥")
    
    result = await exchange_rates.get_usd_irr_rate()
    formatted_result = exchange_rates.format_exchange_rate_result(result)
    
    try:
        await update.message.reply_text(formatted_result, parse_mode=ParseMode.MARKDOWN)
    except Exception as e:
        logger.error(f"Error sending exchange rate message: {e}")
        # Fall back to plain text if Markdown fails
        await update.message.reply_text(formatted_result.replace('*', '').replace('[', '').replace(']', ''))

async def toman_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Send current USD/Toman exchange rate when the command /toman is issued."""
    await update.message.reply_text("ÿØÿ± ÿ≠ÿßŸÑ ÿØÿ±€åÿßŸÅÿ™ ŸÜÿ±ÿÆ ÿØŸÑÿßÿ± ÿ®Ÿá ÿ™ŸàŸÖÿßŸÜ... ‚è≥")
    
    result = await exchange_rates.get_usd_toman_rate()
    
    if result.get("success", False):
        # Format the rate with commas for thousands
        try:
            rate_value = float(result.get("current_rate", "0"))
            formatted_rate = f"{rate_value:,.0f}"
            
            message = (
                f"üíµ *ŸÜÿ±ÿÆ ÿØŸÑÿßÿ± ÿ¢ŸÖÿ±€å⁄©ÿß ÿ®Ÿá ÿ™ŸàŸÖÿßŸÜ*\n\n"
                f"ŸÜÿ±ÿÆ ŸÅÿπŸÑ€å: *{formatted_rate} ÿ™ŸàŸÖÿßŸÜ*\n"
                f"ÿ™ÿ∫€å€åÿ±ÿßÿ™: {result.get('change_percent', 'N/A')}\n"
                f"ŸÖŸÜÿ®ÿπ: [tgju.org]({result.get('source_url', 'https://www.tgju.org')})\n"
                f"ÿ≤ŸÖÿßŸÜ ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å: {datetime.datetime.fromisoformat(result.get('timestamp', datetime.datetime.now().isoformat())).strftime('%Y-%m-%d %H:%M:%S')}"
            )
            
            await update.message.reply_text(message, parse_mode=ParseMode.MARKDOWN)
        except Exception as e:
            logger.error(f"Error formatting toman rate: {e}")
            await update.message.reply_text(f"ŸÜÿ±ÿÆ ÿØŸÑÿßÿ± ÿ®Ÿá ÿ™ŸàŸÖÿßŸÜ: {result.get('current_rate', 'N/A')} ÿ™ŸàŸÖÿßŸÜ")
    else:
        await update.message.reply_text(f"‚ùå ÿÆÿ∑ÿß ÿØÿ± ÿØÿ±€åÿßŸÅÿ™ ŸÜÿ±ÿÆ ÿØŸÑÿßÿ± ÿ®Ÿá ÿ™ŸàŸÖÿßŸÜ: {result.get('error', 'ÿÆÿ∑ÿß€å ŸÜÿßŸÖÿ¥ÿÆÿµ')}")

def is_exchange_rate_request(text: str) -> bool:
    """
    Check if a message is asking about exchange rates.
    
    Args:
        text: The message text to check
        
    Returns:
        True if it's an exchange rate request, False otherwise
    """
    if not text:
        return False
        
    # Keywords related to exchange rates in Persian and English
    keywords = [
        "ŸÜÿ±ÿÆ ÿØŸÑÿßÿ±", "ŸÇ€åŸÖÿ™ ÿØŸÑÿßÿ±", "ŸÇ€åŸÖÿ™ ÿßÿ±ÿ≤", "ÿØŸÑÿßÿ± ⁄ÜŸÜÿØŸá", "ÿØŸÑÿßÿ± ⁄ÜŸÜÿØ ÿ¥ÿØŸá", "ÿØŸÑÿßÿ± ⁄ÜŸÇÿØÿ± ÿ¥ÿØŸá",
        "ÿ™ÿ®ÿØ€åŸÑ ÿØŸÑÿßÿ±", "ÿ™ÿ®ÿØ€åŸÑ ÿ™ŸàŸÖÿßŸÜ", "ÿ™ÿ®ÿØ€åŸÑ ÿ±€åÿßŸÑ", "ÿßÿ±ÿ≤ ÿ¢ŸÖÿ±€å⁄©ÿß", "usd", "dollar rate",
        "ÿØŸÑÿßÿ± ÿ¢ŸÖÿ±€å⁄©ÿß", "ÿØŸÑÿßÿ± ÿ®Ÿá ÿ™ŸàŸÖÿßŸÜ", "ÿØŸÑÿßÿ± ÿ®Ÿá ÿ±€åÿßŸÑ"
    ]
    
    text_lower = text.lower()
    return any(keyword in text_lower for keyword in keywords)

def main() -> None:
    """Start the bot."""
    # Get the Telegram token from environment variable
    token = os.getenv("TELEGRAM_TOKEN")
    if not token:
        logger.error("No TELEGRAM_TOKEN environment variable found!")
        return

    # Ensure database is initialized
    database.initialize_database()
    
    # Initialize memory
    memory.initialize_memory()

    # Create the Application
    application = Application.builder().token(token).build()

    # Add handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("dollar", dollar_command))
    application.add_handler(CommandHandler("toman", toman_command))
    # Process all messages to check for mentions
    application.add_handler(MessageHandler(filters.ALL & ~filters.COMMAND, handle_message))

    # Log startup
    logger.info("Bot started, waiting for messages...")

    # Run the bot until the user presses Ctrl-C
    application.run_polling()

if __name__ == "__main__":
    main() 